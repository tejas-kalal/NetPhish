{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eM0O2cIwAHfk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import csv\n",
        "import traceback\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException\n",
        "import re\n",
        "from dateutil import parser\n",
        "import signal\n",
        "import urllib.parse\n",
        "import tldextract\n",
        "from urllib.parse import urlparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9PNCNZWOA6iL"
      },
      "outputs": [],
      "source": [
        "# Function to extract features from a URL\n",
        "def extract_url_features(url):\n",
        "    # Parse the URL\n",
        "    parsed_url = urlparse(url)\n",
        "\n",
        "    # Feature 1: URL length\n",
        "    url_length = len(url)\n",
        "\n",
        "    # Feature 2: Number of dots in the URL\n",
        "    num_dots = url.count('.')\n",
        "\n",
        "    # Feature 3: Presence of hyphen in domain\n",
        "    has_hyphen = 1 if re.search(r'-', parsed_url.netloc) else 0\n",
        "\n",
        "    # Feature 4: Presence of '@' symbol\n",
        "    has_at_symbol = 1 if re.search(r'@', url) else 0\n",
        "\n",
        "    # Feature 5: URL path length\n",
        "    path_length = len(parsed_url.path)\n",
        "\n",
        "    # Feature 6: Query parameter length\n",
        "    query_length = len(parsed_url.query)\n",
        "\n",
        "    # Feature 7: Number of URL parameters\n",
        "    num_params = int(len(parsed_url.query.split('&'))) if parsed_url.query else 0\n",
        "\n",
        "    # Feature 8: Top-level domain (TLD) length\n",
        "    tld_info = tldextract.extract(url)\n",
        "    tld_length = len(tld_info.suffix)\n",
        "\n",
        "    # Feature 9: Use of HTTPS\n",
        "    uses_https = 1 if re.search(r'https', url) else 0\n",
        "\n",
        "    # Feature 10: URL depth (number of '/' in path)\n",
        "    url_depth = parsed_url.path.count('/')\n",
        "\n",
        "    # Feature 11: Presence of IP address in domain\n",
        "    ip_pattern = re.compile(r'(\\d{1,3}\\.){3}\\d{1,3}')\n",
        "    netloc_without_port = parsed_url.netloc.split(':')[0]  # Remove port number if present\n",
        "    has_ip = 1 if ip_pattern.search(netloc_without_port) else 0\n",
        "\n",
        "    # Feature 12: Length of the domain\n",
        "    domain_length = int(len(parsed_url.netloc))\n",
        "\n",
        "    # Feature 13: Number of subdomains\n",
        "    num_subdomains = len(parsed_url.netloc.split('.')) - 2\n",
        "\n",
        "    # Feature 14: Presence of suspicious words (e.g., 'login', 'secure', 'account')\n",
        "    suspicious_words = ['login', 'secure', 'account', 'webscr', 'banking', 'confirm', 'verification']\n",
        "    contains_suspicious_word = 0\n",
        "    for word in suspicious_words:\n",
        "        if word in url.lower():\n",
        "            contains_suspicious_word = 1\n",
        "            break\n",
        "\n",
        "    # Feature 15: Length of the hostname\n",
        "    hostname_length = int(len(parsed_url.hostname)) if parsed_url.hostname else 0\n",
        "\n",
        "    # Feature 16: Use of port in URL\n",
        "    has_port = 1 if parsed_url.port else 0\n",
        "\n",
        "    # Feature 17: Number of special characters in the URL (like '?', '=', '#', etc.)\n",
        "    special_chars = ['?', '=', '#', '%', '&']\n",
        "    num_special_chars = sum([url.count(char) for char in special_chars])\n",
        "\n",
        "    # Feature 18: Whether the URL is shortened (e.g., using bit.ly, tinyurl)\n",
        "    shortening_services = ['bit.ly', 'tinyurl.com', 'goo.gl', 'shorte.st', 'go2l.ink', 'x.co', 'ow.ly', 't.co']\n",
        "    is_shortened = 1 if any(service in url.lower() for service in shortening_services) else 0\n",
        "\n",
        "    # Feature 19: Length of the URL fragment (after '#')\n",
        "    fragment_length = int(len(parsed_url.fragment)) if parsed_url.fragment else 0\n",
        "\n",
        "    # Feature 20: Position of the first occurrence of \"//\" in the URL\n",
        "    double_slash_pos = url.find('//')\n",
        "\n",
        "    # Feature 21: Ratio of digits to the total length of the URL\n",
        "    digit_count = sum(c.isdigit() for c in url)\n",
        "    digit_to_length_ratio = digit_count / url_length if url_length > 0 else 0\n",
        "\n",
        "    # Feature 22: Number of unique characters in the URL\n",
        "    num_unique_chars = len(set(url))\n",
        "\n",
        "    # Feature 23: Presence of hexadecimal characters (indicative of encoded URLs)\n",
        "    has_hex_chars = 1 if re.search(r'%[0-9a-fA-F]{2}', url) else 0\n",
        "\n",
        "    # Feature 24: Length of the file extension (if present)\n",
        "    file_extension = parsed_url.path.split('.')[-1] if '.' in parsed_url.path else ''\n",
        "    file_extension_length = len(file_extension)\n",
        "\n",
        "    # Feature 25: Number of underscores ('_') in the URL\n",
        "    num_underscores = url.count('_')\n",
        "\n",
        "\n",
        "    netcraft_url = f\"https://sitereport.netcraft.com/?url={url}\"\n",
        "    driver.get(netcraft_url)\n",
        "    WebDriverWait(driver, 10).until(\n",
        "                EC.presence_of_element_located((By.TAG_NAME, \"body\"))\n",
        "            )\n",
        "\n",
        "    html_content = driver.page_source\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # bagroung section - 2 features\n",
        "    baground_section = soup.find('section', {'id': 'background_table_section'})\n",
        "    date_first_seen = None\n",
        "    domain_age_days = None\n",
        "    site_rank = None\n",
        "\n",
        "    if baground_section:\n",
        "      rows = baground_section.find_all('tr')\n",
        "      for row in rows:\n",
        "        th = row.find('th')\n",
        "        if th and \"Site rank\" in th.text: #need to adjust Not Present\n",
        "          td = row.find('td')\n",
        "          site_rank = td.text.strip()\n",
        "          try:\n",
        "            site_rank = int(site_rank)\n",
        "          except:\n",
        "            site_rank = None\n",
        "        if th and \"Date first seen\" in th.text:\n",
        "          td = row.find('td')\n",
        "          date_first_seen = td.text.strip()\n",
        "          break\n",
        "\n",
        "    if date_first_seen:\n",
        "      try:\n",
        "        first_seen_date = datetime.strptime(date_first_seen, \"%B %Y\")\n",
        "        current_date = datetime.now()\n",
        "        domain_age_days = (current_date - first_seen_date).days\n",
        "      except:\n",
        "        domain_age_days = None\n",
        "\n",
        "    # network Section - 5 features\n",
        "    network_section = soup.find('section', {'id': 'network_table_section'})\n",
        "    asn = None\n",
        "    reverse_dns_present = None\n",
        "    netblock_owner = None\n",
        "    organisation = None\n",
        "    dnsssec = None\n",
        "\n",
        "    if network_section:\n",
        "      rows = network_section.find_all('tr')\n",
        "      for row in rows:\n",
        "        th = row.find('th')\n",
        "        if th and \"Netblock Owner\" in th.text:\n",
        "          td = row.find('td')\n",
        "          netblock_owner = td.text.strip()\n",
        "        if th and \"IPv4 autonomous systems\" in th.text:\n",
        "          anchor = row.find('a')\n",
        "          asn = anchor.text.strip()\n",
        "          asn = asn[2:]\n",
        "        if th and \"Reverse DNS\" in th.text:\n",
        "          td = row.find('td')\n",
        "          reverse_dns = td.text.strip()\n",
        "          if reverse_dns not in [\"Unknown\",\"Not available\"]:\n",
        "            reverse_dns_present = 1\n",
        "          else:\n",
        "            reverse_dns_present = 0\n",
        "        if th and \"Organisation\" in th.text:\n",
        "          td = row.find('td')\n",
        "          organisation = td.text.strip()\n",
        "          if organisation not in [\"Unknown\",\"Not available\"]:\n",
        "            organisation = 1\n",
        "          else:\n",
        "            organisation = 0\n",
        "        if th and \"DNS Security Extensions\" in th.text:\n",
        "          td = row.find('td')\n",
        "          dnsssec = td.text.strip()\n",
        "          if dnsssec == \"Enabled\":\n",
        "            dnsssec = 1\n",
        "          else:\n",
        "            dnsssec = 0\n",
        "          break\n",
        "\n",
        "      # Collect all the features in a list\n",
        "    features = [\n",
        "    url_length, num_dots, has_hyphen, has_at_symbol, path_length, query_length,\n",
        "    num_params, tld_length, uses_https, url_depth, has_ip, domain_length,\n",
        "    num_subdomains, contains_suspicious_word, hostname_length, has_port,\n",
        "    num_special_chars, is_shortened, fragment_length, double_slash_pos,\n",
        "    digit_to_length_ratio, num_unique_chars, has_hex_chars, file_extension_length,\n",
        "    num_underscores, domain_age_days, site_rank, netblock_owner, asn,\n",
        "    reverse_dns_present, organisation, dnsssec]\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0KdGTw7zC1ie"
      },
      "outputs": [],
      "source": [
        "# Load the input CSV file\n",
        "file_path = 'legitimate_urls_chunk_no_22.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "feature_names = [\n",
        "    \"url_length\", \"num_dots\", \"has_hyphen\", \"has_at_symbol\", \"path_length\", \"query_length\",\n",
        "    \"num_params\", \"tld_length\", \"uses_https\", \"url_depth\", \"has_ip\", \"domain_length\",\n",
        "    \"num_subdomains\", \"contains_suspicious_word\", \"hostname_length\", \"has_port\",\n",
        "    \"num_special_chars\", \"is_shortened\", \"fragment_length\", \"double_slash_pos\",\n",
        "    \"digit_to_length_ratio\", \"num_unique_chars\", \"has_hex_chars\", \"file_extension_length\",\n",
        "    \"num_underscores\", \"domain_age_days\", \"site_rank\", \"netblock_owner\", \"asn\",\n",
        "    \"reverse_dns_present\", \"organisation\", \"dnsssec\",\"class\"\n",
        "]\n",
        "\n",
        "# Create the DataFrame with the first row for column titles\n",
        "features_df = pd.DataFrame(columns=feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOom2d31DpdK",
        "outputId": "bf1ee94f-6373-44ea-da70-67a54256dd1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 357/1878 [33:03<1:37:36,  3.85s/it]/tmp/ipykernel_2461/1056605614.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  features_df.loc[len(features_df)] = data_row\n",
            " 71%|███████   | 1331/1878 [2:04:51<51:18,  5.63s/it]  \n"
          ]
        },
        {
          "ename": "WebDriverException",
          "evalue": "Message: unknown error: net::ERR_INTERNET_DISCONNECTED\n  (Session info: chrome=136.0.7103.94)\nStacktrace:\n#0 0x5ed611fc775a <unknown>\n#1 0x5ed611a6a0a0 <unknown>\n#2 0x5ed611a61177 <unknown>\n#3 0x5ed611a52199 <unknown>\n#4 0x5ed611a53e8d <unknown>\n#5 0x5ed611a5252e <unknown>\n#6 0x5ed611a51ece <unknown>\n#7 0x5ed611a51ba2 <unknown>\n#8 0x5ed611a4f9ef <unknown>\n#9 0x5ed611a501aa <unknown>\n#10 0x5ed611a6d5d9 <unknown>\n#11 0x5ed611b07eb5 <unknown>\n#12 0x5ed611ae13a2 <unknown>\n#13 0x5ed611b072a0 <unknown>\n#14 0x5ed611ae1173 <unknown>\n#15 0x5ed611aadd4b <unknown>\n#16 0x5ed611aae9b1 <unknown>\n#17 0x5ed611f8c90b <unknown>\n#18 0x5ed611f9080a <unknown>\n#19 0x5ed611f74662 <unknown>\n#20 0x5ed611f91394 <unknown>\n#21 0x5ed611f5949f <unknown>\n#22 0x5ed611fb5538 <unknown>\n#23 0x5ed611fb5716 <unknown>\n#24 0x5ed611fc65c6 <unknown>\n#25 0x75c14609caa4 <unknown>\n#26 0x75c146129c3c <unknown>\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mWebDriverException\u001b[39m                        Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m tqdm(df.iterrows(), total=\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[32m     10\u001b[39m     url = row[\u001b[33m'\u001b[39m\u001b[33mURL\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     features = \u001b[43mextract_url_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     class_label = \u001b[32m1\u001b[39m\n\u001b[32m     15\u001b[39m     data_row = features + [class_label]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mextract_url_features\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m     91\u001b[39m num_underscores = url.count(\u001b[33m'\u001b[39m\u001b[33m_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     94\u001b[39m netcraft_url = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhttps://sitereport.netcraft.com/?url=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetcraft_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m WebDriverWait(driver, \u001b[32m10\u001b[39m).until(\n\u001b[32m     97\u001b[39m             EC.presence_of_element_located((By.TAG_NAME, \u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     98\u001b[39m         )\n\u001b[32m    100\u001b[39m html_content = driver.page_source\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/phish_dataset/phish/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:454\u001b[39m, in \u001b[36mWebDriver.get\u001b[39m\u001b[34m(self, url)\u001b[39m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    437\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Navigate the browser to the specified URL in the current window or\u001b[39;00m\n\u001b[32m    438\u001b[39m \u001b[33;03m    tab.\u001b[39;00m\n\u001b[32m    439\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    452\u001b[39m \u001b[33;03m    >>> driver.get(\"https://example.com\")\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43murl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/phish_dataset/phish/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:429\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    427\u001b[39m response = \u001b[38;5;28mself\u001b[39m.command_executor.execute(driver_command, params)\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m     response[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._unwrap_value(response.get(\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/phish_dataset/phish/lib/python3.12/site-packages/selenium/webdriver/remote/errorhandler.py:232\u001b[39m, in \u001b[36mErrorHandler.check_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    230\u001b[39m         alert_text = value[\u001b[33m\"\u001b[39m\u001b[33malert\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
            "\u001b[31mWebDriverException\u001b[39m: Message: unknown error: net::ERR_INTERNET_DISCONNECTED\n  (Session info: chrome=136.0.7103.94)\nStacktrace:\n#0 0x5ed611fc775a <unknown>\n#1 0x5ed611a6a0a0 <unknown>\n#2 0x5ed611a61177 <unknown>\n#3 0x5ed611a52199 <unknown>\n#4 0x5ed611a53e8d <unknown>\n#5 0x5ed611a5252e <unknown>\n#6 0x5ed611a51ece <unknown>\n#7 0x5ed611a51ba2 <unknown>\n#8 0x5ed611a4f9ef <unknown>\n#9 0x5ed611a501aa <unknown>\n#10 0x5ed611a6d5d9 <unknown>\n#11 0x5ed611b07eb5 <unknown>\n#12 0x5ed611ae13a2 <unknown>\n#13 0x5ed611b072a0 <unknown>\n#14 0x5ed611ae1173 <unknown>\n#15 0x5ed611aadd4b <unknown>\n#16 0x5ed611aae9b1 <unknown>\n#17 0x5ed611f8c90b <unknown>\n#18 0x5ed611f9080a <unknown>\n#19 0x5ed611f74662 <unknown>\n#20 0x5ed611f91394 <unknown>\n#21 0x5ed611f5949f <unknown>\n#22 0x5ed611fb5538 <unknown>\n#23 0x5ed611fb5716 <unknown>\n#24 0x5ed611fc65c6 <unknown>\n#25 0x75c14609caa4 <unknown>\n#26 0x75c146129c3c <unknown>\n"
          ]
        }
      ],
      "source": [
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"--disable-gpu\")\n",
        "chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    url = row['URL']\n",
        "    features = extract_url_features(url)\n",
        "\n",
        "    class_label = 1\n",
        "\n",
        "    data_row = features + [class_label]\n",
        "\n",
        "    # Append the data to the DataFrame\n",
        "    features_df.loc[len(features_df)] = data_row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KDWwiiNkEAdC"
      },
      "outputs": [],
      "source": [
        "#save data to output file.\n",
        "features_df.to_csv('/home/tejas/Desktop/phish_dataset/dataset_chunks/legitimate_dataset_chunk_22A.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "phish",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
